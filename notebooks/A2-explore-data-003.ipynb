{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "from collections import defaultdict, Counter\n",
    "from unidecode import unidecode\n",
    "from typing import List, Tuple, Dict, Union\n",
    "import log\n",
    "import mynlputils as nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = log.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(raw_txt_train_path: str, raw_txt_test_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df_train = pd.read_excel(raw_txt_train_path)\n",
    "    df_test = pd.read_excel(raw_txt_test_path)\n",
    "    logger.info(f\"df_train.shape: {df_train.shape}\")\n",
    "    logger.info(f\"df_train unique tokens: {df_train['Token'].nunique()}\")\n",
    "    logger.info(f\"df_train unique POS: {df_train['POS'].nunique()}\")\n",
    "    logger.info(f\"df_test.shape: {df_test.shape}\")\n",
    "    logger.info(f\"df_test unique tokens: {df_test['Token'].nunique()}\")\n",
    "    logger.info(f\"df_test unique POS: {df_test['POS'].nunique()}\")\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def remove_punctuation(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Removes rows with 'PUNCT' in the 'POS' column from the dataset.\n",
    "\n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame containing the tokenized isiZulu data with 'Token' and 'POS' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with rows containing 'PUNCT' removed.\n",
    "    \"\"\"\n",
    "    return data[data['POS'] != 'PUNCT']\n",
    "\n",
    "\n",
    "def split_sentences(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Splits the dataset into sentences based on rows with NaN values and add start and end tokens.\n",
    "\n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame containing the tokenized isiZulu data with 'Token' and 'POS' columns.\n",
    "\n",
    "    Returns:\n",
    "    list: List of sentences, where each sentence is a list of tuples (Token, POS).\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for _, row in data.iterrows():\n",
    "        if pd.isnull(row['Token']) and pd.isnull(row['POS']):\n",
    "            if sentence:\n",
    "                sentence = [('<s>', 'START')] + sentence + [('</s>', 'STOP')]\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "        else:\n",
    "            sentence.append((row['Token'], row['POS']))\n",
    "    if sentence:\n",
    "        sentence = [('<s>', 'START')] + sentence + [('</s>', 'STOP')]\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def compute_transition_probabilities(sentences: List[Tuple[str, str]], smoothing: float) -> dict:\n",
    "    \"\"\"\n",
    "    Computes transition probabilities for the Hidden Markov Model (HMM) based on the given sentences.\n",
    "\n",
    "    Args:\n",
    "    sentences (List[Tuple[str, str]]): List of sentences where each sentence is a tuple of (token, POS).\n",
    "    smoothing (float): Smoothing parameter for Laplace smoothing. Default is 0.0 for no smoothing.\n",
    "\n",
    "    Returns:\n",
    "    dict: Transition probabilities for the HMM.\n",
    "    \"\"\"\n",
    "    transition_counts = {}\n",
    "    transition_probabilities = {}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for i in range(1, len(sentence) - 1):  # we start from 1 and end at len(sentence) - 1 to exclude <s> and </s>\n",
    "            current_token, current_pos = sentence[i]\n",
    "            next_token, next_pos = sentence[i + 1]\n",
    "\n",
    "            if current_pos not in transition_counts:\n",
    "                transition_counts[current_pos] = {}\n",
    "\n",
    "            if next_pos not in transition_counts[current_pos]:\n",
    "                transition_counts[current_pos][next_pos] = smoothing\n",
    "\n",
    "            transition_counts[current_pos][next_pos] += 1\n",
    "\n",
    "    for current_pos, next_pos_counts in transition_counts.items():\n",
    "        total_count = sum(next_pos_counts.values())\n",
    "        transition_probabilities[current_pos] = {}\n",
    "\n",
    "        for next_pos, count in next_pos_counts.items():\n",
    "            if smoothing == 0.0:\n",
    "                transition_probabilities[current_pos][next_pos] = count / total_count\n",
    "            else:\n",
    "                transition_probabilities[current_pos][next_pos] = (count + smoothing) / (total_count + smoothing * len(transition_counts))\n",
    "                # Number of unique tags instead of transition_counts. \n",
    "    return transition_probabilities\n",
    "\n",
    "\n",
    "# def compute_emission_probabilities(sentences: List[Tuple[str, str]], smoothing: float) -> dict:\n",
    "#     \"\"\"\n",
    "#     Computes emission probabilities for the Hidden Markov Model (HMM) based on the given sentences.\n",
    "\n",
    "#     Args:\n",
    "#     sentences (List[Tuple[str, str]]): List of sentences where each sentence is a tuple of (token, POS).\n",
    "#     smoothing (float): Smoothing parameter for Laplace smoothing. Default is 0.0 for no smoothing.\n",
    "\n",
    "#     Returns:\n",
    "#     dict: Emission probabilities for the HMM.\n",
    "#     \"\"\"\n",
    "#     emission_counts = {}\n",
    "#     emission_probabilities = {}\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         for token, pos in sentence[1:-1]:  # we exclude <s> and </s> tokens\n",
    "#             if pos not in emission_counts:\n",
    "#                 emission_counts[pos] = {}\n",
    "\n",
    "#             if token not in emission_counts[pos]:\n",
    "#                 emission_counts[pos][token] = smoothing\n",
    "\n",
    "#             emission_counts[pos][token] += 1\n",
    "\n",
    "#     for pos, token_counts in emission_counts.items():\n",
    "#         total_count = sum(token_counts.values())\n",
    "#         emission_probabilities[pos] = {}\n",
    "\n",
    "#         for token, count in token_counts.items():\n",
    "#             if smoothing == 0.0:\n",
    "#                 emission_probabilities[pos][token] = count / total_count\n",
    "#             else:\n",
    "#                 emission_probabilities[pos][token] = (count + smoothing) / (total_count + smoothing * len(emission_counts))\n",
    "#                 # Number of words instead of emission_counts.\n",
    "#     return emission_probabilities\n",
    "\n",
    "\n",
    "def compute_emission_probabilities(sentences: List[Tuple[str, str]], smoothing: float) -> dict:\n",
    "    \"\"\"\n",
    "    Computes emission probabilities for the Hidden Markov Model (HMM) based on the given sentences.\n",
    "\n",
    "    Args:\n",
    "    sentences (List[Tuple[str, str]]): List of sentences where each sentence is a tuple of (token, POS).\n",
    "    smoothing (float): Smoothing parameter for Laplace smoothing. Default is 0.0 for no smoothing.\n",
    "\n",
    "    Returns:\n",
    "    dict: Emission probabilities for the HMM.\n",
    "    \"\"\"\n",
    "    emission_counts = {}\n",
    "    emission_probabilities = {}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for token, pos in sentence[1:-1]:  # we exclude <s> and </s> tokens\n",
    "            if pos not in emission_counts:\n",
    "                emission_counts[pos] = {}\n",
    "\n",
    "            if token not in emission_counts[pos]:\n",
    "                emission_counts[pos][token] = smoothing\n",
    "\n",
    "            emission_counts[pos][token] += 1\n",
    "\n",
    "    # Count total number of words in vocabulary (including unknown word)\n",
    "    vocab_size = sum(len(token_counts) for token_counts in emission_counts.values()) + 1\n",
    "\n",
    "    for pos, token_counts in emission_counts.items():\n",
    "        total_count = sum(token_counts.values())\n",
    "        emission_probabilities[pos] = {}\n",
    "\n",
    "        for token, count in token_counts.items():\n",
    "            if smoothing == 0.0:\n",
    "                emission_probabilities[pos][token] = count / total_count\n",
    "            else:\n",
    "                emission_probabilities[pos][token] = (count + smoothing) / (total_count + smoothing * vocab_size)\n",
    "\n",
    "        # Add probability for unknown word\n",
    "        emission_probabilities[pos]['<UNK>'] = smoothing / (total_count + smoothing * vocab_size)\n",
    "\n",
    "    return emission_probabilities\n",
    "\n",
    "\n",
    "def train(sentences_train, smoothing):\n",
    "    transitions = compute_transition_probabilities(sentences_train, smoothing) # Compute transition probabilities\n",
    "    emissions = compute_emission_probabilities(sentences_train, smoothing) # Compute emission probabilities\n",
    "    return {'transitions': transitions, 'emissions': emissions} # Create and return the trained HMM model\n",
    "\n",
    "\n",
    "def evaluate_hmm_model(test_sentences: List[Tuple[str, str]], transition_probabilities: dict, emission_probabilities: dict) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates the Hidden Markov Model (HMM) on the test sentences and returns the accuracy.\n",
    "\n",
    "    Args:\n",
    "    test_sentences (List[Tuple[str, str]]): List of test sentences where each sentence is a tuple of (token, POS).\n",
    "    transition_probabilities (dict): Transition probabilities for the HMM.\n",
    "    emission_probabilities (dict): Emission probabilities for the HMM.\n",
    "\n",
    "    Returns:\n",
    "    float: Accuracy of the HMM on the test sentences.\n",
    "    \"\"\"\n",
    "    total_tokens = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for sentence in test_sentences:\n",
    "        tokens = [token for token, _ in sentence]\n",
    "        true_pos_tags = [pos for _, pos in sentence]\n",
    "        predicted_pos_tags = tag_sentence(tokens, transition_probabilities, emission_probabilities)\n",
    "\n",
    "        total_tokens += len(tokens)\n",
    "        correct_predictions += sum(1 for true_pos, predicted_pos in zip(true_pos_tags, predicted_pos_tags) if true_pos == predicted_pos)\n",
    "\n",
    "    accuracy = correct_predictions / total_tokens\n",
    "    return round(accuracy * 100, 2)\n",
    "\n",
    "\n",
    "# def tag_sentence(tokens: List[str], transition_probabilities: dict, emission_probabilities: dict) -> List[str]:\n",
    "#     \"\"\"\n",
    "#     Tags a sentence with part-of-speech (POS) tags using the Hidden Markov Model (HMM).\n",
    "\n",
    "#     Args:\n",
    "#     tokens (List[str]): List of tokens in the sentence.\n",
    "#     transition_probabilities (dict): Transition probabilities for the HMM.\n",
    "#     emission_probabilities (dict): Emission probabilities for the HMM.\n",
    "\n",
    "#     Returns:\n",
    "#     List[str]: List of predicted POS tags for the sentence.\n",
    "#     \"\"\"\n",
    "#     n = len(tokens)\n",
    "#     viterbi = []\n",
    "\n",
    "#     # Initialization\n",
    "#     viterbi.append({})\n",
    "#     for pos in transition_probabilities.keys():\n",
    "#         if pos == 'START':\n",
    "#             viterbi[0][pos] = 1\n",
    "#         else:\n",
    "#             viterbi[0][pos] = 0\n",
    "\n",
    "#     # Recursion\n",
    "#     for t in range(1, n):\n",
    "#         viterbi.append({})\n",
    "#         for pos in transition_probabilities.keys():\n",
    "#             max_prob = max(\n",
    "#                 viterbi[t - 1][prev_pos] * transition_probabilities[prev_pos].get(pos, 0) * emission_probabilities[pos].get(tokens[t], 0)\n",
    "#                 for prev_pos in transition_probabilities)\n",
    "#             viterbi[t][pos] = max_prob\n",
    "\n",
    "#     # Termination\n",
    "#     for pos in transition_probabilities.keys():\n",
    "#         transition_prob = transition_probabilities[pos].get('STOP', 0)\n",
    "#         viterbi[-1][pos] *= transition_prob\n",
    "\n",
    "#     # Backtracking\n",
    "#     optimal_path = []\n",
    "#     max_prob_pos = max(viterbi[-1], key=viterbi[-1].get)\n",
    "#     optimal_path.append(max_prob_pos)\n",
    "#     for t in range(n - 2, -1, -1):\n",
    "#         max_prob_pos = max(viterbi[t], key=viterbi[t].get)\n",
    "#         optimal_path.insert(0, max_prob_pos)\n",
    "\n",
    "#     return optimal_path\n",
    "\n",
    "def tag_sentence(tokens: List[str], transition_probabilities: dict, emission_probabilities: dict) -> List[str]:\n",
    "    \"\"\"\n",
    "    Tags a sentence with part-of-speech (POS) tags using the Hidden Markov Model (HMM).\n",
    "\n",
    "    Args:\n",
    "    tokens (List[str]): List of tokens in the sentence.\n",
    "    transition_probabilities (dict): Transition probabilities for the HMM.\n",
    "    emission_probabilities (dict): Emission probabilities for the HMM.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: List of predicted POS tags for the sentence.\n",
    "    \"\"\"\n",
    "    n = len(tokens)\n",
    "    viterbi = []\n",
    "\n",
    "    # Replace unknown words with '<UNK>'\n",
    "    tokens = [token if token in emission_probabilities else '<UNK>' for token in tokens]\n",
    "\n",
    "    # Initialization\n",
    "    viterbi.append({})\n",
    "    for pos in transition_probabilities.keys():\n",
    "        if pos == 'START':\n",
    "            viterbi[0][pos] = 1\n",
    "        else:\n",
    "            viterbi[0][pos] = 0\n",
    "\n",
    "    # Recursion\n",
    "    for t in range(1, n):\n",
    "        viterbi.append({})\n",
    "        for pos in transition_probabilities.keys():\n",
    "            max_prob = max(\n",
    "                viterbi[t - 1][prev_pos] * transition_probabilities[prev_pos].get(pos, 0) * emission_probabilities[pos].get(tokens[t], 0)\n",
    "                for prev_pos in transition_probabilities)\n",
    "            viterbi[t][pos] = max_prob\n",
    "\n",
    "    # Termination\n",
    "    for pos in transition_probabilities.keys():\n",
    "        transition_prob = transition_probabilities[pos].get('STOP', 0)\n",
    "        viterbi[-1][pos] *= transition_prob\n",
    "\n",
    "    # Backtracking\n",
    "    optimal_path = []\n",
    "    max_prob_pos = max(viterbi[-1], key=viterbi[-1].get)\n",
    "    optimal_path.append(max_prob_pos)\n",
    "    for t in range(n - 2, -1, -1):\n",
    "        max_prob_pos = max(viterbi[t], key=viterbi[t].get)\n",
    "        optimal_path.insert(0, max_prob_pos)\n",
    "\n",
    "    return optimal_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15-Jul-23 23:26:15 - INFO - Starting 'load_config'.\n",
      "15-Jul-23 23:26:15 - INFO - Finished 'load_config' in 0.0081 secs.\n",
      "15-Jul-23 23:26:15 - INFO - df_train.shape: (44324, 2)\n",
      "15-Jul-23 23:26:15 - INFO - df_train unique tokens: 14125\n",
      "15-Jul-23 23:26:15 - INFO - df_train unique POS: 99\n",
      "15-Jul-23 23:26:15 - INFO - df_test.shape: (4676, 2)\n",
      "15-Jul-23 23:26:15 - INFO - df_test unique tokens: 2415\n",
      "15-Jul-23 23:26:15 - INFO - df_test unique POS: 77\n",
      "15-Jul-23 23:26:16 - INFO - Number of training sentences: 2216\n",
      "15-Jul-23 23:26:16 - INFO - Number of validation sentences: 392\n",
      "15-Jul-23 23:26:16 - INFO - Number of test sentences: 333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = nu.load_config(\"a2\")\n",
    "df_train, df_test = load_data(conf.paths.raw_txt_train, conf.paths.raw_txt_test)\n",
    "df_train = remove_punctuation(df_train)\n",
    "df_test = remove_punctuation(df_test)\n",
    "# Split sentences for training and test sets\n",
    "sentences_train, sentences_valid = train_test_split(split_sentences(df_train), test_size=0.15, random_state=42)\n",
    "sentences_test = split_sentences(df_test)\n",
    "logger.info(f\"Number of training sentences: {len(sentences_train)}\")\n",
    "logger.info(f\"Number of validation sentences: {len(sentences_valid)}\")\n",
    "logger.info(f\"Number of test sentences: {len(sentences_test)}\")\n",
    "model = train(sentences_train, conf.model.smoothing)\n",
    "accuracy = evaluate_hmm_model(sentences_valid, model['transitions'], model['emissions'])\n",
    "accuracy # = round(accuracy * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlai_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
