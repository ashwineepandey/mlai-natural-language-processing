{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import string\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import log\n",
    "import mynlputils as nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = log.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nu.timer\n",
    "def load_data(raw_txt_train_path: str, raw_txt_test_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df_train = pd.read_csv(raw_txt_train_path, header=None, names=[\"label\", \"title\", \"description\"])\n",
    "    df_test = pd.read_csv(raw_txt_test_path, header=None, names=[\"label\", \"title\", \"description\"])\n",
    "    return df_train[[\"label\", \"description\"]], df_test[[\"label\", \"description\"]]\n",
    "\n",
    "@nu.timer\n",
    "def create_validation_set(corpus: pd.DataFrame, valid_size: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train_corpus, valid_corpus = train_test_split(corpus, test_size=valid_size, random_state=1)\n",
    "    return train_corpus.reset_index(drop=True), valid_corpus.reset_index(drop=True)\n",
    "\n",
    "@nu.timer\n",
    "def clean_text(docs: pd.DataFrame) -> pd.DataFrame:\n",
    "    clean_docs = docs['description']\n",
    "    clean_docs = clean_docs.str.replace(\"-\", \" \")\n",
    "    clean_docs = clean_docs.str.replace(\"quot;\", \" \")\n",
    "    clean_docs = clean_docs.str.replace(\"#39;s\", \"'\")\n",
    "    translation_table = str.maketrans('', '', string.punctuation)\n",
    "    clean_docs = clean_docs.str.translate(translation_table)\n",
    "    clean_docs = clean_docs.str.lower()\n",
    "    clean_docs = clean_docs.str.replace(r'\\d+', ' <NUM> ')\n",
    "    clean_docs = clean_docs.str.replace(r'\\s+', ' ')\n",
    "    return clean_docs.to_frame()\n",
    "\n",
    "@nu.timer\n",
    "def split_docs(docs: pd.DataFrame) -> pd.DataFrame:\n",
    "    return docs['description'].str.split().to_list()\n",
    "\n",
    "@nu.timer\n",
    "def tokenize(tokens: List[List[str]], min_freq: int = 5):\n",
    "    word_freq = Counter([word for sentence in tokens for word in sentence])\n",
    "    vocab = [word for word, freq in word_freq.items() if freq >= min_freq]\n",
    "    vocab = ['<PAD>', '<UNK>'] + vocab\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx_tokens = [[word2idx.get(word, 1) for word in sentence] for sentence in tokens]\n",
    "    return vocab, idx_tokens, word2idx\n",
    "\n",
    "@nu.timer\n",
    "def create_skipgrams(corpus, window_size, pad_idx):\n",
    "    data = []\n",
    "    for sentence in corpus:\n",
    "        padded_sentence = [pad_idx] * window_size + sentence + [pad_idx] * window_size\n",
    "        for word_index in range(window_size, len(padded_sentence) - window_size):\n",
    "            contexts = padded_sentence[word_index - window_size : word_index] + padded_sentence[word_index + 1 : word_index + window_size + 1]\n",
    "            data.append((contexts, padded_sentence[word_index]))\n",
    "    return data\n",
    "\n",
    "@nu.timer\n",
    "def create_batches(skipgrams, word2idx, pad_idx, batch_size=32, num_neg_samples=5):\n",
    "    words_list = list(word2idx.keys())\n",
    "    vocab_size = len(words_list)\n",
    "    n = len(skipgrams)\n",
    "\n",
    "    # Shuffle skipgrams\n",
    "    random.shuffle(skipgrams)\n",
    "\n",
    "    batches = []\n",
    "\n",
    "    for batch_start in range(0, n, batch_size):\n",
    "        context_batch = []\n",
    "        target_batch = []\n",
    "        negative_batch = []\n",
    "\n",
    "        # Create batches\n",
    "        for contexts, target in skipgrams[batch_start:batch_start + batch_size]:\n",
    "            negatives = [random.choice(range(vocab_size)) for _ in range(num_neg_samples)]\n",
    "            context_batch.append(torch.LongTensor(contexts))\n",
    "            target_batch.append(torch.LongTensor([target]))\n",
    "            negative_batch.append(torch.LongTensor(negatives))\n",
    "\n",
    "        # If this is the last batch and it's not full, skip it\n",
    "        if len(context_batch) < batch_size:\n",
    "            continue\n",
    "\n",
    "        # Pad context sequences in batch\n",
    "        context_batch = pad_sequence(context_batch, batch_first=True, padding_value=pad_idx)\n",
    "\n",
    "        # Convert target and negative batches to tensors\n",
    "        target_batch = torch.stack(target_batch)\n",
    "        negative_batch = torch.stack(negative_batch)\n",
    "\n",
    "        batches.append((context_batch, target_batch, negative_batch))\n",
    "        \n",
    "    return batches\n",
    "\n",
    "\n",
    "class CBOW_NS(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super(CBOW_NS, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "    def forward(self, context_words, target_word, negative_words):\n",
    "        # Get embeddings for context words, target word and negative words\n",
    "        context_embeds = self.embeddings(context_words)  # (batch_size, window_size*2, embed_size)\n",
    "        target_embeds = self.embeddings(target_word)    # (batch_size, 1, embed_size)\n",
    "        negative_embeds = self.embeddings(negative_words)# (batch_size, num_neg_samples, embed_size)\n",
    "\n",
    "        # Sum the context word embeddings\n",
    "        context_embeds_sum = torch.sum(context_embeds, dim=1, keepdim=True)  # (batch_size, 1, embed_size)\n",
    "\n",
    "        # Compute positive score\n",
    "        pos_score = torch.bmm(context_embeds_sum, target_embeds.transpose(1,2)) # (batch_size, 1, 1)\n",
    "        pos_score = F.logsigmoid(pos_score)\n",
    "\n",
    "        # Compute negative score\n",
    "        neg_score = torch.bmm(context_embeds_sum, negative_embeds.transpose(1,2)) # (batch_size, 1, num_neg_samples)\n",
    "        neg_score = F.logsigmoid(-neg_score)\n",
    "\n",
    "        # Return negative of total score\n",
    "        return -(torch.sum(pos_score) + torch.sum(neg_score))\n",
    "    \n",
    "@nu.timer\n",
    "def train(model, epochs, train_batches, val_batches, lr):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        for context_batch, target_batch, negative_batch in train_batches:\n",
    "            model.zero_grad()\n",
    "            loss = model(context_batch, target_batch, negative_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "        train_loss = total_loss / batch_count\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()  # set model to eval mode\n",
    "        val_loss = evaluate(model, val_batches)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        logger.info(f'Epoch {epoch}, Train Loss: {train_loss}, Validation Loss: {val_loss}')\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "\n",
    "def evaluate(model, batches):\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    with torch.no_grad():  # disable gradient computation to save memory\n",
    "        for context_batch, target_batch, negative_batch in batches:\n",
    "            loss = model(context_batch, target_batch, negative_batch)\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "    return total_loss / batch_count\n",
    "\n",
    "\n",
    "# def train(model, epochs, batches, lr=0.001):\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     losses = []\n",
    "#     for epoch in range(epochs):\n",
    "#         total_loss = 0\n",
    "#         batch_count = 0\n",
    "#         for context_batch, target_batch, negative_batch in batches:\n",
    "#             model.zero_grad()\n",
    "#             loss = model(context_batch, target_batch, negative_batch)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "#             batch_count += 1\n",
    "#         avg_loss = total_loss / batch_count\n",
    "#         losses.append(avg_loss)\n",
    "#         logger.info(f'Epoch {epoch}, Loss: {avg_loss}')\n",
    "#     return model, losses\n",
    "\n",
    "\n",
    "# def plot_losses(losses, epochs):\n",
    "#     # Plotting the losses\n",
    "#     fig = px.line(x=list(range(epochs)), y=losses, labels={'x':'Epochs', 'y':'Loss'}, title='Loss over time')\n",
    "#     fig.show()\n",
    "\n",
    "def plot_losses(train_losses, val_losses, epochs):\n",
    "    epochs_range = list(range(1, epochs + 1))\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=epochs_range, y=train_losses, mode='lines', name='Train Loss'))\n",
    "    fig.add_trace(go.Scatter(x=epochs_range, y=val_losses, mode='lines', name='Validation Loss'))\n",
    "    fig.update_layout(title='Loss over Epochs', xaxis=dict(title='Epoch'), yaxis=dict(title='Loss'))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-Jul-23 23:20:50 - INFO - Starting 'load_config'.\n",
      "23-Jul-23 23:20:50 - INFO - Finished 'load_config' in 0.0091 secs.\n",
      "23-Jul-23 23:20:50 - INFO - Starting 'load_data'.\n",
      "23-Jul-23 23:20:51 - INFO - Finished 'load_data' in 0.3090 secs.\n",
      "23-Jul-23 23:20:51 - INFO - Starting 'create_validation_set'.\n",
      "23-Jul-23 23:20:51 - INFO - Finished 'create_validation_set' in 0.0076 secs.\n",
      "23-Jul-23 23:20:51 - INFO - Starting 'clean_text'.\n",
      "/var/folders/0g/blggksdj42z52nv3fy0h5b880000gn/T/ipykernel_45598/538010891.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  clean_docs = clean_docs.str.replace(r'\\d+', ' <NUM> ')\n",
      "/var/folders/0g/blggksdj42z52nv3fy0h5b880000gn/T/ipykernel_45598/538010891.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  clean_docs = clean_docs.str.replace(r'\\s+', ' ')\n",
      "23-Jul-23 23:20:52 - INFO - Finished 'clean_text' in 1.4277 secs.\n",
      "23-Jul-23 23:20:52 - INFO - Starting 'clean_text'.\n",
      "23-Jul-23 23:20:52 - INFO - Finished 'clean_text' in 0.1509 secs.\n",
      "23-Jul-23 23:20:52 - INFO - Starting 'clean_text'.\n",
      "23-Jul-23 23:20:52 - INFO - Finished 'clean_text' in 0.1046 secs.\n",
      "23-Jul-23 23:20:52 - INFO - Starting 'split_docs'.\n",
      "23-Jul-23 23:20:53 - INFO - Finished 'split_docs' in 0.3422 secs.\n",
      "23-Jul-23 23:20:53 - INFO - Starting 'split_docs'.\n",
      "23-Jul-23 23:20:53 - INFO - Finished 'split_docs' in 0.0263 secs.\n",
      "23-Jul-23 23:20:53 - INFO - Starting 'split_docs'.\n",
      "23-Jul-23 23:20:53 - INFO - Finished 'split_docs' in 0.0126 secs.\n",
      "23-Jul-23 23:20:53 - INFO - Starting 'tokenize'.\n",
      "23-Jul-23 23:20:54 - INFO - Finished 'tokenize' in 0.7463 secs.\n",
      "23-Jul-23 23:20:54 - INFO - Starting 'tokenize'.\n",
      "23-Jul-23 23:20:54 - INFO - Finished 'tokenize' in 0.0628 secs.\n",
      "23-Jul-23 23:20:54 - INFO - Starting 'tokenize'.\n",
      "23-Jul-23 23:20:54 - INFO - Finished 'tokenize' in 0.0376 secs.\n",
      "23-Jul-23 23:20:54 - INFO - Starting 'create_skipgrams'.\n",
      "23-Jul-23 23:20:57 - INFO - Finished 'create_skipgrams' in 3.2830 secs.\n",
      "23-Jul-23 23:20:57 - INFO - Starting 'create_skipgrams'.\n",
      "23-Jul-23 23:20:57 - INFO - Finished 'create_skipgrams' in 0.5124 secs.\n",
      "23-Jul-23 23:20:57 - INFO - Starting 'create_skipgrams'.\n",
      "23-Jul-23 23:20:58 - INFO - Finished 'create_skipgrams' in 0.0650 secs.\n",
      "23-Jul-23 23:20:58 - INFO - Starting 'create_batches'.\n",
      "23-Jul-23 23:21:28 - INFO - Finished 'create_batches' in 30.7277 secs.\n",
      "23-Jul-23 23:21:28 - INFO - Starting 'create_batches'.\n",
      "23-Jul-23 23:21:32 - INFO - Finished 'create_batches' in 3.2626 secs.\n",
      "23-Jul-23 23:21:32 - INFO - Starting 'create_batches'.\n",
      "23-Jul-23 23:21:34 - INFO - Finished 'create_batches' in 2.2139 secs.\n"
     ]
    }
   ],
   "source": [
    "conf = nu.load_config(\"a3\")\n",
    "df_train, df_test = load_data(conf.paths.raw_txt_train, conf.paths.raw_txt_test)\n",
    "df_train, df_valid = create_validation_set(df_train, 0.1)\n",
    "df_train_clean = clean_text(df_train)\n",
    "df_valid_clean = clean_text(df_valid)\n",
    "df_test_clean = clean_text(df_test)\n",
    "\n",
    "train_tokens = split_docs(df_train_clean)\n",
    "valid_tokens = split_docs(df_valid_clean)\n",
    "test_tokens = split_docs(df_test_clean)\n",
    "\n",
    "vocab, idx_train_tokens, word2idx = tokenize(train_tokens)\n",
    "_, idx_valid_tokens, _ = tokenize(valid_tokens)\n",
    "_, idx_test_tokens, _ = tokenize(test_tokens)\n",
    "\n",
    "pad_idx = word2idx['<PAD>']\n",
    "skipgrams_train = create_skipgrams(idx_train_tokens, window_size=2, pad_idx=pad_idx)\n",
    "skipgrams_valid = create_skipgrams(idx_valid_tokens, window_size=2, pad_idx=pad_idx)\n",
    "skipgrams_test = create_skipgrams(idx_test_tokens, window_size=2, pad_idx=pad_idx)\n",
    "\n",
    "train_batches = create_batches(skipgrams_train, word2idx, pad_idx, batch_size=512)\n",
    "valid_batches = create_batches(skipgrams_valid, word2idx, pad_idx, batch_size=512)\n",
    "test_batches = create_batches(skipgrams_test, word2idx, pad_idx, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-Jul-23 23:21:34 - INFO - Starting 'train'.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vocab_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(vocab)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m CBOW_NS(vocab_size, conf\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39membed_size)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trained_model, train_losses, val_losses \u001b[39m=\u001b[39m train(model, conf\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mepochs, train_batches, valid_batches, conf\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mlr)\n",
      "File \u001b[0;32m~/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/mynlputils.py:24\u001b[0m, in \u001b[0;36mtimer.<locals>.wrapper_timer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarting \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m---> 24\u001b[0m value \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     25\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m     26\u001b[0m run_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;32m/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb Cell 5\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, train_batches, val_batches, lr)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb#W4sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m loss \u001b[39m=\u001b[39m model(context_batch, target_batch, negative_batch)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb#W4sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb#W4sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb#W4sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb#W4sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m batch_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_nlp/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_nlp/lib/python3.9/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_nlp/lib/python3.9/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_nlp/lib/python3.9/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_nlp/lib/python3.9/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "model = CBOW_NS(vocab_size, conf.model.embed_size)\n",
    "trained_model, train_losses, val_losses = train(model, conf.model.epochs, train_batches, valid_batches, conf.model.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CBOW_NS(vocab_size, conf.model.embed_size)\n",
    "model.load_state_dict(torch.load(\"../data/06_models/ap_news/cbow_ns_23072023_183858.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-natural-language-processing/notebooks/A3-explore-data-007.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plot_losses(train_losses, val_losses, conf\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mepochs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plot_losses(train_losses, val_losses, conf.model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.save_pytorch_model(trained_model, file_path=f\"{conf.paths.models}cbow_ns_{nu._get_current_dt()}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve the embeddings from the model\n",
    "embeddings = model.embeddings.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between nasa and space: 0.4396308660507202\n",
      "Similarity between car and bus: 0.18682055175304413\n",
      "Similarity between cat and dog: 0.057477667927742004\n"
     ]
    }
   ],
   "source": [
    "# Define pairs of words\n",
    "word_pairs = [('nasa', 'space'), ('car', 'bus'), ('cat', 'dog')]\n",
    "\n",
    "# Calculate cosine similarities\n",
    "for word1, word2 in word_pairs:\n",
    "    idx1 = word2idx[word1]\n",
    "    idx2 = word2idx[word2]\n",
    "    sim = cosine_similarity([embeddings[idx1]], [embeddings[idx2]])\n",
    "    print(f\"Similarity between {word1} and {word2}: {sim[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlai_nlp/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:795: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlai_nlp/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:805: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=3, random_state=42)  # reduce to 3 components\n",
    "embeddings_tsne = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {value: key for key, value in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(embeddings_tsne, columns=['Dim1', 'Dim2', 'Dim3'])\n",
    "df['word'] = idx2word.values()  # assuming idx2word is your index to word mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of words you're interested in\n",
    "words = vocab[:100]  # replace with your words\n",
    "df_subset = df[df['word'].isin(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Dim1=%{x}<br>Dim2=%{y}<br>Dim3=%{z}<br>word=%{text}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "scene": "scene",
         "showlegend": false,
         "text": [
          "<PAD>",
          "<UNK>",
          "homemaking",
          "icon",
          "martha",
          "stewart",
          "will",
          "serve",
          "her",
          "five",
          "month",
          "jail",
          "sentence",
          "for",
          "lying",
          "about",
          "a",
          "suspicious",
          "stock",
          "sale",
          "at",
          "minimum",
          "security",
          "prison",
          "in",
          "west",
          "virginia",
          "source",
          "close",
          "to",
          "the",
          "case",
          "said",
          "wednesday",
          "as",
          "online",
          "piracy",
          "reaches",
          "epidemic",
          "proportions",
          "motion",
          "picture",
          "association",
          "of",
          "america",
          "is",
          "buckling",
          "down",
          "on",
          "internet",
          "controversy",
          "erupted",
          "campus",
          "october",
          "when",
          "ordered",
          "nairobi",
          "reuters",
          "sudans",
          "government",
          "and",
          "southern",
          "rebels",
          "vowed",
          "friday",
          "end",
          "africas",
          "longest",
          "civil",
          "war",
          "by",
          "dec",
          "<NUM>",
          "signing",
          "pledge",
          "front",
          "un",
          "council",
          "envoys",
          "who",
          "flew",
          "from",
          "new",
          "york",
          "demand",
          "fighting",
          "stop",
          "secretary",
          "general",
          "kofi",
          "annan",
          "received",
          "an",
          "unusual",
          "standing",
          "ovation",
          "nation",
          "assembly",
          "following",
          "calls"
         ],
         "type": "scatter3d",
         "x": [
          -13.092723846435547,
          -13.601207733154297,
          18.930736541748047,
          -1.0027995109558105,
          2.2342875003814697,
          2.0603437423706055,
          -16.423219680786133,
          -5.470832347869873,
          -18.07573699951172,
          4.851284027099609,
          2.149716377258301,
          1.353347897529602,
          7.19766092300415,
          -14.368522644042969,
          -5.247105598449707,
          -13.410706520080566,
          -14.33581829071045,
          -21.210769653320312,
          -3.48184871673584,
          -11.53852367401123,
          -11.959110260009766,
          12.035872459411621,
          -6.03823184967041,
          5.210080623626709,
          -12.354241371154785,
          1.3546395301818848,
          5.507805824279785,
          -8.98265552520752,
          -1.8040006160736084,
          -15.787097930908203,
          -13.664896965026855,
          0.09328750520944595,
          -13.293286323547363,
          -12.48017692565918,
          -13.92387580871582,
          -8.950987815856934,
          -10.311416625976562,
          21.19232749938965,
          -8.758938789367676,
          26.903532028198242,
          1.461350679397583,
          -6.126913547515869,
          0.7527288198471069,
          -12.71711540222168,
          3.1473701000213623,
          -15.004514694213867,
          -15.747344970703125,
          -14.42944622039795,
          -13.448314666748047,
          -9.740416526794434,
          11.418633460998535,
          4.695003509521484,
          -27.78253173828125,
          13.368657112121582,
          -14.343916893005371,
          3.003863573074341,
          1.5476590394973755,
          -12.351666450500488,
          5.164002895355225,
          -3.5923690795898438,
          -13.324407577514648,
          2.5506107807159424,
          -23.29420280456543,
          -8.889891624450684,
          -12.579419136047363,
          -0.8415359854698181,
          4.302365303039551,
          2.869523048400879,
          4.85450553894043,
          6.999783039093018,
          -13.798444747924805,
          17.503786087036133,
          -13.979734420776367,
          -0.21802759170532227,
          -15.438179016113281,
          2.9265029430389404,
          -5.457119464874268,
          -5.790359020233154,
          -15.273835182189941,
          -16.434467315673828,
          -1.1373965740203857,
          -12.855510711669922,
          -14.158830642700195,
          -3.799682140350342,
          -9.199687957763672,
          -0.3197338283061981,
          -13.343807220458984,
          -0.6832231283187866,
          -7.9355149269104,
          -28.374370574951172,
          -27.927202224731445,
          7.580252647399902,
          -14.846847534179688,
          -6.569704532623291,
          6.722781658172607,
          7.340529918670654,
          3.9154891967773438,
          -1.7489241361618042,
          2.012845993041992,
          -8.715871810913086
         ],
         "y": [
          -39.55821228027344,
          -38.98838424682617,
          33.17176055908203,
          22.34181022644043,
          -12.71962833404541,
          -12.800675392150879,
          -36.58974838256836,
          12.579595565795898,
          -31.482044219970703,
          -8.05716323852539,
          -8.04379940032959,
          -2.5806779861450195,
          1.292184591293335,
          -38.211090087890625,
          3.580637216567993,
          -33.449493408203125,
          -39.43147659301758,
          -21.2174129486084,
          -9.622903823852539,
          11.604762077331543,
          -37.47282028198242,
          -9.593456268310547,
          -10.315068244934082,
          -6.687592506408691,
          -39.59162139892578,
          -22.46592140197754,
          -12.912087440490723,
          -6.742397785186768,
          2.4669852256774902,
          -38.9517936706543,
          -39.99142074584961,
          1.0495631694793701,
          -38.57095718383789,
          -31.983076095581055,
          -36.964500427246094,
          -7.987244129180908,
          -17.385805130004883,
          -19.345321655273438,
          -2.283504009246826,
          9.600983619689941,
          -11.9593505859375,
          -4.713085174560547,
          -12.904073715209961,
          -39.51591110229492,
          -14.027958869934082,
          -36.24518585205078,
          -16.446332931518555,
          -28.444786071777344,
          -39.03022384643555,
          -9.141047477722168,
          -6.510672092437744,
          -1.2098742723464966,
          -16.053340911865234,
          -0.15217415988445282,
          -30.898771286010742,
          -5.037375450134277,
          -33.757545471191406,
          -37.118961334228516,
          -15.118724822998047,
          -15.834038734436035,
          -38.00291061401367,
          -18.1572208404541,
          -23.591354370117188,
          8.70295524597168,
          -31.27730941772461,
          -0.4610939025878906,
          -25.07600975036621,
          8.217862129211426,
          -21.43718719482422,
          -19.993968963623047,
          -35.450111389160156,
          -1.8953970670700073,
          -40.51377868652344,
          3.512955904006958,
          16.78273582458496,
          2.474764585494995,
          -19.15487289428711,
          -19.614492416381836,
          22.74498748779297,
          -33.24546813964844,
          1.651814341545105,
          -35.920936584472656,
          -38.12134552001953,
          -11.414053916931152,
          -5.063811302185059,
          1.4522241353988647,
          10.553218841552734,
          -16.063560485839844,
          -21.619916915893555,
          -3.0665533542633057,
          -3.1103012561798096,
          -1.0817965269088745,
          -36.3743896484375,
          -20.450122833251953,
          30.943927764892578,
          30.47488021850586,
          -15.835789680480957,
          -26.4755802154541,
          -5.413260459899902,
          5.838010787963867
         ],
         "z": [
          11.525171279907227,
          11.064461708068848,
          14.627171516418457,
          11.775754928588867,
          28.050764083862305,
          28.41910743713379,
          11.143895149230957,
          -23.2879581451416,
          14.678390502929688,
          2.048940896987915,
          2.734767436981201,
          -3.468681812286377,
          -9.422453880310059,
          12.366523742675781,
          6.085427284240723,
          9.11142635345459,
          13.322545051574707,
          3.7589852809906006,
          -6.581921100616455,
          11.362017631530762,
          11.852009773254395,
          -23.191984176635742,
          2.5635762214660645,
          -1.1403160095214844,
          12.300413131713867,
          -0.5561570525169373,
          13.61678409576416,
          7.080844402313232,
          -5.299801826477051,
          11.923699378967285,
          12.578140258789062,
          8.054193496704102,
          10.644118309020996,
          10.345635414123535,
          11.15757942199707,
          2.3944647312164307,
          5.162595272064209,
          7.6104583740234375,
          -16.264110565185547,
          -6.749007701873779,
          11.853803634643555,
          21.07463836669922,
          10.835260391235352,
          13.246465682983398,
          -0.14362743496894836,
          10.705099105834961,
          38.926002502441406,
          8.713142395019531,
          12.246953964233398,
          3.3431010246276855,
          3.998669147491455,
          -8.600993156433105,
          23.58311653137207,
          -3.645423173904419,
          9.546871185302734,
          20.832788467407227,
          1.276873230934143,
          9.987447738647461,
          -2.8031911849975586,
          -0.6099230647087097,
          11.619369506835938,
          -0.8640012741088867,
          10.793251037597656,
          -5.500396251678467,
          10.108491897583008,
          0.02379750646650791,
          -15.352967262268066,
          19.116825103759766,
          -17.716079711914062,
          -18.662630081176758,
          9.907340049743652,
          1.2638165950775146,
          11.402013778686523,
          9.040571212768555,
          7.193228244781494,
          8.710806846618652,
          -0.286223828792572,
          -0.45979398488998413,
          -2.633253812789917,
          8.947375297546387,
          0.1113855317234993,
          11.308294296264648,
          10.723236083984375,
          4.23825740814209,
          -7.983026504516602,
          -6.970659255981445,
          3.276287794113159,
          6.858085632324219,
          6.45147180557251,
          -1.2380391359329224,
          -1.1720830202102661,
          2.472273826599121,
          12.93315601348877,
          11.3497896194458,
          7.027351379394531,
          7.058079242706299,
          4.428070068359375,
          -21.178194046020508,
          -0.8555671572685242,
          -3.3015782833099365
         ]
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "Dim1"
          }
         },
         "yaxis": {
          "title": {
           "text": "Dim2"
          }
         },
         "zaxis": {
          "title": {
           "text": "Dim3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "fig = px.scatter_3d(df_subset, x='Dim1', y='Dim2', z='Dim3', text='word')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2)  # reduce to 2 components\n",
    "embeddings_pca = pca.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vocab[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vocab = sorted(vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'beijing' in sorted_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some words\n",
    "words = ['china', 'beijing', 'russia', 'moscow', 'japan', 'tokyo', 'france', 'paris', 'germany', 'berlin']  # replace with your words\n",
    "for word in words:\n",
    "    idx = word2idx[word]\n",
    "    plt.scatter(embeddings_pca[idx, 0], embeddings_pca[idx, 1])\n",
    "    plt.annotate(word, (embeddings_pca[idx, 0], embeddings_pca[idx, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings(embedding, word, word2idx, idx2word, n=10):\n",
    "    # Get the embedding for the word\n",
    "    word_embedding = embedding[word2idx[word]]\n",
    "\n",
    "    # Compute cosine similarities between word_embedding and all embeddings\n",
    "    similarities = cosine_similarity([word_embedding], embedding)[0]\n",
    "\n",
    "    # Get the indices of the top n similar embeddings\n",
    "    closest_idxs = np.argsort(similarities)[-n:]\n",
    "\n",
    "    # Convert these indices back to words and return\n",
    "    closest_words_with_distances = [(idx2word[idx], similarities[idx]) for idx in reversed(closest_idxs)]\n",
    "\n",
    "    return closest_words_with_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('referendum', 1.0), ('recall', 0.40677977), ('ginter', 0.40064535), ('analyze', 0.39800185), ('concept', 0.3958459), ('oak', 0.38121623)]\n"
     ]
    }
   ],
   "source": [
    "word = \"referendum\"\n",
    "n = 6\n",
    "print(find_closest_embeddings(embeddings, word, word2idx, idx2word, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('venezuela', 1.0), ('davie', 0.40575475), ('uncommon', 0.38389525), ('traditionally', 0.3790345), ('steato', 0.37682575), ('bosnians', 0.37576467)]\n"
     ]
    }
   ],
   "source": [
    "word = \"venezuela\"\n",
    "n = 6\n",
    "print(find_closest_embeddings(embeddings, word, word2idx, idx2word, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('war', 1.0), ('torn', 0.53540725), ('terror', 0.52566016), ('between', 0.511223), ('against', 0.41544825), ('crimes', 0.40494663)]\n"
     ]
    }
   ],
   "source": [
    "word = \"war\"\n",
    "n = 6\n",
    "print(find_closest_embeddings(embeddings, word, word2idx, idx2word, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pope', 1.0), ('allens', 0.50665796), ('leopard', 0.39513463), ('loopholes', 0.39341122), ('grouse', 0.38507998), ('sally', 0.37698418)]\n"
     ]
    }
   ],
   "source": [
    "word = \"pope\"\n",
    "n = 6\n",
    "print(find_closest_embeddings(embeddings, word, word2idx, idx2word, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('schumacher', 1.0), ('michael', 0.41150188), ('eisner', 0.3847862), ('circus', 0.36715344), ('symbolic', 0.36696625), ('gameplay', 0.36256465)]\n"
     ]
    }
   ],
   "source": [
    "word = \"schumacher\"\n",
    "n = 6\n",
    "print(find_closest_embeddings(embeddings, word, word2idx, idx2word, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ferrari', 1.0), ('madison', 0.3909257), ('sheer', 0.37503532), ('rockers', 0.36956292), ('philosophical', 0.3661985), ('ddr', 0.36431968)]\n"
     ]
    }
   ],
   "source": [
    "word = \"ferrari\"\n",
    "n = 6\n",
    "print(find_closest_embeddings(embeddings, word, word2idx, idx2word, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('soccer', 0.9999999), ('league', 0.4791219), ('player', 0.47478947), ('teams', 0.4713383), ('team', 0.46328172), ('field', 0.45484388)]\n"
     ]
    }
   ],
   "source": [
    "word = \"soccer\"\n",
    "n = 6\n",
    "print(find_closest_embeddings(embeddings, word, word2idx, idx2word, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cricket', 1.0), ('title', 0.44584304), ('india', 0.426397), ('council', 0.4262874), ('test', 0.42543542), ('morning', 0.39616194)]\n"
     ]
    }
   ],
   "source": [
    "word = \"cricket\"\n",
    "n = 6\n",
    "print(find_closest_embeddings(embeddings, word, word2idx, idx2word, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
