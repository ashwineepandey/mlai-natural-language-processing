{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "from collections import defaultdict, Counter\n",
    "from unidecode import unidecode\n",
    "from typing import List, Tuple, Dict, Union\n",
    "import log\n",
    "import mynlputils as nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = log.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(raw_txt_train_path: str, raw_txt_test_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df_train = pd.read_excel(raw_txt_train_path)\n",
    "    df_test = pd.read_excel(raw_txt_test_path)\n",
    "    logger.info(f\"df_train.shape: {df_train.shape}\")\n",
    "    logger.info(f\"df_train unique tokens: {df_train['Token'].nunique()}\")\n",
    "    logger.info(f\"df_train unique POS: {df_train['POS'].nunique()}\")\n",
    "    logger.info(f\"df_test.shape: {df_test.shape}\")\n",
    "    logger.info(f\"df_test unique tokens: {df_test['Token'].nunique()}\")\n",
    "    logger.info(f\"df_test unique POS: {df_test['POS'].nunique()}\")\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def remove_punctuation(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Removes rows with 'PUNCT' in the 'POS' column from the dataset.\n",
    "\n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame containing the tokenized isiZulu data with 'Token' and 'POS' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with rows containing 'PUNCT' removed.\n",
    "    \"\"\"\n",
    "    return data[data['POS'] != 'PUNCT']\n",
    "\n",
    "\n",
    "def split_into_sentences(df: pd.DataFrame) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into a list of DataFrames each representing a sentence.\n",
    "    Adds start and stop tokens to each sentence.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing the tokenized isiZulu data with 'Token' and 'POS' columns.\n",
    "\n",
    "    Returns:\n",
    "    List[pd.DataFrame]: List of DataFrames each representing a sentence.\n",
    "    \"\"\"\n",
    "    df['Sentence'] = (df['Token'].isna().cumsum())\n",
    "    df = df.dropna()\n",
    "    sentences = [group for _, group in df.groupby('Sentence')]\n",
    "    for i in range(len(sentences)):\n",
    "        start_token = pd.DataFrame([['<s>', 'START']], columns=['Token', 'POS'])\n",
    "        stop_token = pd.DataFrame([['<\\s>', 'STOP']], columns=['Token', 'POS'])\n",
    "        sentences[i] = pd.concat([start_token, sentences[i], stop_token], ignore_index=True)\n",
    "    return sentences\n",
    "\n",
    "def create_validation_set(sentences: List[pd.DataFrame], valid_size: float = 0.2) -> Tuple[List[pd.DataFrame], List[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Creates a validation set from a list of DataFrames each representing a sentence.\n",
    "\n",
    "    Args:\n",
    "    sentences (List[pd.DataFrame]): List of DataFrames each representing a sentence.\n",
    "    valid_size (float): Proportion of sentences to include in the validation set.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[List[pd.DataFrame], List[pd.DataFrame]]: Training and validation sets.\n",
    "    \"\"\"\n",
    "    train_sentences, valid_sentences = train_test_split(sentences, test_size=valid_size, random_state=1)\n",
    "    return train_sentences, valid_sentences\n",
    "\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self):\n",
    "        self.transition_probs = dict()\n",
    "        self.emission_probs = dict()\n",
    "        self.start_probs = dict()\n",
    "\n",
    "@nu.timer\n",
    "def train_hmm(sentences: List[pd.DataFrame]) -> HMM:\n",
    "    \"\"\"\n",
    "    Trains a Hidden Markov Model (HMM) given a list of sentences. Applies Laplace smoothing when calculating probabilities.\n",
    "\n",
    "    Args:\n",
    "    sentences (List[pd.DataFrame]): List of DataFrames, each representing a sentence.\n",
    "\n",
    "    Returns:\n",
    "    HMM: Trained HMM model.\n",
    "    \"\"\"\n",
    "    model = HMM()\n",
    "\n",
    "    transition_counts = defaultdict(int)\n",
    "    emission_counts = defaultdict(int)\n",
    "    start_counts = defaultdict(int)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        prev_tag = None\n",
    "        for _, row in sentence.iterrows():\n",
    "            token, tag = row['Token'], row['POS']\n",
    "            if prev_tag is None:\n",
    "                start_counts[tag] += 1\n",
    "            else:\n",
    "                transition_counts[(prev_tag, tag)] += 1\n",
    "            emission_counts[(tag, token)] += 1\n",
    "            prev_tag = tag\n",
    "\n",
    "    unique_transitions = len(transition_counts)\n",
    "    unique_emissions = len(emission_counts)\n",
    "\n",
    "    total_transitions = sum(transition_counts.values())\n",
    "    total_emissions = sum(emission_counts.values())\n",
    "    total_starts = sum(start_counts.values())\n",
    "\n",
    "    model.transition_probs = {k: (v + 1) / (total_transitions + unique_transitions) for k, v in transition_counts.items()}\n",
    "    model.emission_probs = {k: (v + 1) / (total_emissions + unique_emissions) for k, v in emission_counts.items()}\n",
    "    model.start_probs = {k: v / total_starts for k, v in start_counts.items()}\n",
    "\n",
    "    return model\n",
    "\n",
    "@nu.timer\n",
    "def viterbi_algorithm(model: HMM, sentence: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uses the Viterbi algorithm to find the most probable sequence of hidden states (POS tags).\n",
    "    Handles unknown words by assigning a small constant probability for every state.\n",
    "\n",
    "    Args:\n",
    "    model (HMM): Trained HMM model.\n",
    "    sentence (pd.DataFrame): DataFrame representing a sentence.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the tokens, actual tags, and predicted tags for each sentence.\n",
    "    \"\"\"\n",
    "    tokens = sentence['Token'].tolist()\n",
    "    actual_tags = sentence['POS'].tolist()\n",
    "    states = list(set([state for state, _ in model.emission_probs.keys()]))\n",
    "    n_states = len(states)\n",
    "    n_tokens = len(tokens)\n",
    "\n",
    "    dp = np.zeros((n_states, n_tokens))\n",
    "    ptr = np.zeros((n_states, n_tokens), dtype=int)\n",
    "    unknown_word_prob = 1e-6  # Small constant probability for unknown words\n",
    "\n",
    "    # Initialization\n",
    "    for i, state in enumerate(states):\n",
    "        dp[i, 0] = model.start_probs.get(state, 0) * model.emission_probs.get((state, tokens[0]), unknown_word_prob)\n",
    "\n",
    "    # Recursion\n",
    "    for t in range(1, n_tokens):\n",
    "        for j, state in enumerate(states):\n",
    "            max_prob = 0\n",
    "            max_state = 0\n",
    "            for i, prev_state in enumerate(states):\n",
    "                prob = dp[i, t-1] * model.transition_probs.get((prev_state, state), 0) * model.emission_probs.get((state, tokens[t]), unknown_word_prob)\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_state = i\n",
    "            dp[j, t] = max_prob\n",
    "            ptr[j, t] = max_state\n",
    "\n",
    "    # Traceback\n",
    "    best_path = [np.argmax(dp[:, -1])]\n",
    "    for t in range(n_tokens-1, 0, -1):\n",
    "        best_path.append(ptr[best_path[-1], t])\n",
    "    best_path = [states[i] for i in reversed(best_path)]\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        'Token': tokens,\n",
    "        'Actual_POS': actual_tags,\n",
    "        'Predicted_POS': best_path\n",
    "    })\n",
    "    return result\n",
    "\n",
    "@nu.timer\n",
    "def evaluate_hmm(model: HMM, sentences: List[pd.DataFrame]) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates the performance of the HMM model by calculating the accuracy of POS tagging.\n",
    "\n",
    "    Args:\n",
    "    model (HMM): Trained HMM model.\n",
    "    sentences (List[pd.DataFrame]): List of DataFrames, each representing a sentence.\n",
    "\n",
    "    Returns:\n",
    "    float: Accuracy of POS tagging.\n",
    "    df_results (pd.DataFrame): DataFrame containing the 'Token', 'Actual_POS', and 'Predicted_POS' for each sentence.\n",
    "\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for sentence in sentences:\n",
    "        result = viterbi_algorithm(model, sentence)\n",
    "        results.append(result)\n",
    "    df_results = pd.concat(results, ignore_index=True)\n",
    "    correct_tags = np.sum(df_results['Actual_POS'] == df_results['Predicted_POS'])\n",
    "    total_tags = len(df_results)\n",
    "    accuracy = correct_tags / total_tags\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    return accuracy, df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16-Jul-23 13:12:32 - INFO - Starting 'load_config'.\n",
      "16-Jul-23 13:12:32 - INFO - Finished 'load_config' in 0.0080 secs.\n",
      "16-Jul-23 13:12:32 - INFO - df_train.shape: (44324, 2)\n",
      "16-Jul-23 13:12:32 - INFO - df_train unique tokens: 14125\n",
      "16-Jul-23 13:12:32 - INFO - df_train unique POS: 99\n",
      "16-Jul-23 13:12:32 - INFO - df_test.shape: (4676, 2)\n",
      "16-Jul-23 13:12:32 - INFO - df_test unique tokens: 2415\n",
      "16-Jul-23 13:12:32 - INFO - df_test unique POS: 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7066\n"
     ]
    }
   ],
   "source": [
    "conf = nu.load_config(\"a2\")\n",
    "df_train, df_test = load_data(conf.paths.raw_txt_train, conf.paths.raw_txt_test)\n",
    "df_train = remove_punctuation(df_train)\n",
    "df_test = remove_punctuation(df_test)\n",
    "sentences_train = split_into_sentences(df_train)\n",
    "sentences_test = split_into_sentences(df_test)\n",
    "sentences_train, sentences_valid = create_validation_set(sentences_train)\n",
    "hmm_model = train_hmm(sentences_train)\n",
    "# Evaluate model on the validation set\n",
    "accuracy, df_results = evaluate_hmm(hmm_model, sentences_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlai_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
